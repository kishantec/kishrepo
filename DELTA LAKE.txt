DELTA LAKE
----------------
1)
In a “Data Lake”, like — “Azure Data Lake Storage Gen 2” in “Azure”, where the “Underlying Data” of a “Table” is “Kept” in the “Form” of “Multiple Files” of “Any Format”, it becomes “Very Difficult” to “Perform” the following “Operations” on those “Files” -

Merge Operation
“Updating” a “Record”, which may be “Present” in “Any” of those “Files”
Metadata Handling
Version Controlling 
2) “Delta Lake” is an “Optimized Storage Layer” on “Top” of the “Data Lake
3)In a “Data Lake”, the “Data” can be “Stored” in any “Format”, like — “CSV”, “JSON” etc.

But, when any “Data” is “Tried” to be “Stored” in a “Delta Lake”, it is “Stored” in the “Form” of a “Delta Table”.
Although, the “Delta Table” is “Not” actually a “Table”, but, it is called so because, a “Delta Table” has “All” the “Features” of a “Relational Database Table”.
The “Underlying Data” of a “Delta Table” is “Stored” in the “Compressed Parquet File Format”, i.e., in “snappy. Parquet” File Format.
4) Delta Lake provides ACID transactions, scalable metadata handling, and unifies streaming and batch data processing on top of existing data lakes, such as S3, ADLS, GCS, and HDFS.
5) 
CREATE TABLE delta.`/tmp/delta-table` USING DELTA AS SELECT col1 as id FROM VALUES 0,1,2,3,4;
--SELECT
SELECT * FROM delta.`/tmp/delta-table`;
6)--UPDATE
INSERT OVERWRITE delta.`/tmp/delta-table` SELECT col1 as id FROM VALUES 5,6,7,8,9;

7) Conditional update without overwrite
-- Update every even value by adding 100 to it
UPDATE delta.`/tmp/delta-table` SET id = id + 100 WHERE id % 2 == 0;

-- Delete very even value
DELETE FROM delta.`/tmp/delta-table` WHERE id % 2 == 0;

-- Upsert (merge) new data
CREATE TEMP VIEW newData AS SELECT col1 AS id FROM VALUES 1,3,5,7,9,11,13,15,17,19;

MERGE INTO delta.`/tmp/delta-table` AS oldData
USING newData
ON oldData.id = newData.id
WHEN MATCHED
  THEN UPDATE SET id = newData.id
WHEN NOT MATCHED
  THEN INSERT (id) VALUES (newData.id);

SELECT * FROM delta.`/tmp/delta-table`;

-- CREATE TABLE
CREATE TABLE IF NOT EXISTS default.people10m (
  id INT,
  firstName STRING,
  middleName STRING,
  lastName STRING,
  gender STRING,
  birthDate TIMESTAMP,
  ssn STRING,
  salary INT
) USING DELTA

CREATE OR REPLACE TABLE default.people10m (
  id INT,
  firstName STRING,
  middleName STRING,
  lastName STRING,
  gender STRING,
  birthDate TIMESTAMP,
  ssn STRING,
  salary INT
) USING DELTA



8) Read Versions of Data
--------------------
SELECT * FROM delta.`/tmp/delta-table` VERSION AS OF 0;

9) Write a stream of data to a table
streamingDf = spark.readStream.format("rate").load()
stream = streamingDf.selectExpr("value as id").writeStream.format("delta").option("checkpointLocation", "/tmp/checkpoint").start("/tmp/delta-table")

10)Read a stream of changes from a table

stream2 = spark.readStream.format("delta").load("/tmp/delta-table").writeStream.format("console").start()
11)  Create table using Dataframe

# Create table in the metastore using DataFrame's schema and write data to it
df.write.format("delta").saveAsTable("default.people10m")

# Create or replace partitioned table with path using DataFrame's schema and write/overwrite data to it
df.write.format("delta").mode("overwrite").save("/tmp/delta/people10m")

start -- https://docs.delta.io/latest/delta-batch.html




